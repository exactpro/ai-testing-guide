{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1WDy-njHA1OactsPKEUkdcpU6fr6_QALz","timestamp":1691680879301}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Hands-On Exercise 2: Implement a Simple Perceptron"],"metadata":{"id":"p5F_j6vAfeTp"}},{"cell_type":"markdown","source":["## Task\n","\n","Follow these steps to implement a single-layer perceptron model that learns the logical `AND` function:\n","\n","1) 📈 define a function that calculates the perceptron output based on its input parameters: inputs, weights, and bias;\n","\n","2) 📝 use the truth table for the `AND` logic to define a list of input-output pairs for the perceptron model;\n","\n","3) 🧮 initialise the bias and the vector of weights in the range of `[-0.5, 0.5]`;\n","\n","4) 💻 train the perceptron model to determine the weight values for learning the logical `AND` function."],"metadata":{"id":"qstIENE6hUAi"}},{"cell_type":"markdown","source":["## A Possible Solution"],"metadata":{"id":"WyGdUuUpiMYz"}},{"cell_type":"markdown","source":["### Step 1 - Setting up the environment"],"metadata":{"id":"deUd5MSLjiDS"}},{"cell_type":"markdown","source":["📚 Prior to developing the model, import the Python modules and libraries that will be used for the task:\n","- `random` will help you to generate random numbers"],"metadata":{"id":"ZSKd-l-NjqPA"}},{"cell_type":"code","source":["import random"],"metadata":{"id":"dR2H0fZ7kXHG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2 - Define a perceptron function"],"metadata":{"id":"t7qkCbyakZOH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkfpGEzhq6Zf"},"outputs":[],"source":["def perceptron(tuple_inputs, weights, bias):\n","  \"\"\"\n","  Return perceptron output based on its inputs, weights and bias values.\n","\n","  tuple_inputs: tuple\n","    It is a tuple of input values (x1, x2).\n","  weights: float\n","    It is a list of weights [w1, w2].\n","  bias: float\n","    It is a bias.\n","  \"\"\"\n","\n","  weighted_sum = sum(x * w for x, w in zip(tuple_inputs, weights))\n","  return 1 if (weighted_sum + bias) >= 0 else 0"]},{"cell_type":"markdown","source":["### Step 3 - Define a function for the perceptron training"],"metadata":{"id":"jF6pQwXWk_UJ"}},{"cell_type":"code","source":["def train_perceptron(data, bias, weight_learning_rate=0.1, max_iter=100):\n","  \"\"\"\n","  Return weights for the simple perceptron model after its training.\n","\n","  data: list\n","    It is a list of tuples in the form of (tuple_inputs, output), where tuple_inputs is a tuple of input values (x1, x2),\n","    output is a corresponding output value.\n","  bias: float\n","    It is a bias.\n","  weight_learning_rate: float\n","    It is a positive constant that determines the step size of the weights updates.\n","  max_iter: int\n","    It is the maximum number of epochs to attempt until stopping in case training never converges.\n","  \"\"\"\n","\n","  inputs_number = len(data[0][0])\n","  # Initialise the vector of weights in range of [-0.5, 0.5]\n","  weights = [0.5 - random.random() for _ in range(inputs_number)]\n","  # Train the perceptron model within the max_iter number of epochs\n","  for epoch_number in range(max_iter):\n","    # Track how many inputs were wrong during the training\n","    num_errors = 0\n","    # Track the training results in each epoch\n","    print('Epoch {0}, weights: {1}'.format(epoch_number, [weights[i] for i in range(inputs_number)]))\n","    # Loop over all the training examples:\n","    for tuple_inputs, output in data:\n","      error = output - perceptron(tuple_inputs, weights, bias)\n","      if error != 0:\n","        num_errors += 1\n","        for i in range(len(tuple_inputs)):\n","          weights[i] += weight_learning_rate * error * tuple_inputs[i]\n","    if num_errors == 0:\n","      break\n","  return weights"],"metadata":{"id":"SknT4agxk_hY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 4 - Implement a perceptron model learning simple 'AND' logical function"],"metadata":{"id":"QtMmKaOlnZOc"}},{"cell_type":"code","source":["# Define a list of input-output pairs\n","and_data = [\n"," ((0, 0),  0),\n"," ((0, 1),  0),\n"," ((1, 0),  0),\n"," ((1, 1),  1)\n","]\n","# Initialise the bias in range of [-0.5, 0.5]\n","bias = -0.4\n","# Return weights for the simple perceptron model after its training\n","weights = train_perceptron(and_data, bias, weight_learning_rate=0.1, max_iter=100)\n","\n","print(f'''\\nThe result of perceptron's learning of 'AND' logical function:\n","weigths: {weights}''')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioRSO5ZpFXNd","executionInfo":{"status":"ok","timestamp":1747675801363,"user_tz":-240,"elapsed":14,"user":{"displayName":"Iuliia Emelianova","userId":"13461693391120637206"}},"outputId":"14000add-410e-463b-93ea-303a80e21bb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, weights: [0.12337312373691856, -0.30134678379983026]\n","Epoch 1, weights: [0.22337312373691856, -0.20134678379983026]\n","Epoch 2, weights: [0.32337312373691857, -0.10134678379983025]\n","Epoch 3, weights: [0.4233731237369186, -0.0013467837998302479]\n","Epoch 4, weights: [0.4233731237369186, 0.09865321620016976]\n","Epoch 5, weights: [0.3233731237369186, 0.09865321620016976]\n","\n","The result of perceptron's learning of 'AND' logical function:\n","weigths: [0.3233731237369186, 0.09865321620016976]\n"]}]}]}